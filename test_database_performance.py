#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ€§èƒ½æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ã€è¿æ¥æ± å’Œå¹¶å‘å¤„ç†èƒ½åŠ›
"""

import psycopg2
import time
import threading
import statistics
from typing import Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ•°æ®åº“è¿æ¥é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'database': 'fince_project_prod',
    'user': 'fince_app_project',
    'password': 'postgres',
    'port': 5432
}

def connect_database() -> psycopg2.extensions.connection:
    """è¿æ¥æ•°æ®åº“"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

def test_simple_query_performance(conn: psycopg2.extensions.connection, iterations: int = 100) -> Dict:
    """æµ‹è¯•ç®€å•æŸ¥è¯¢æ€§èƒ½"""
    print(f"\nğŸ” æµ‹è¯•ç®€å•æŸ¥è¯¢æ€§èƒ½ ({iterations} æ¬¡è¿­ä»£)...")
    
    cursor = conn.cursor()
    times = []
    
    for i in range(iterations):
        start_time = time.time()
        cursor.execute("SELECT COUNT(*) FROM information_schema.tables;")
        cursor.fetchone()
        end_time = time.time()
        times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    cursor.close()
    
    avg_time = statistics.mean(times)
    min_time = min(times)
    max_time = max(times)
    std_dev = statistics.stdev(times) if len(times) > 1 else 0
    
    print(f"   ğŸ“Š å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ms")
    print(f"   ğŸ“Š æœ€å¿«æŸ¥è¯¢æ—¶é—´: {min_time:.2f}ms")
    print(f"   ğŸ“Š æœ€æ…¢æŸ¥è¯¢æ—¶é—´: {max_time:.2f}ms")
    print(f"   ğŸ“Š æ ‡å‡†å·®: {std_dev:.2f}ms")
    
    return {
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'std_dev': std_dev,
        'times': times
    }

def test_complex_query_performance(conn: psycopg2.extensions.connection, iterations: int = 50) -> Dict:
    """æµ‹è¯•å¤æ‚æŸ¥è¯¢æ€§èƒ½"""
    print(f"\nğŸ” æµ‹è¯•å¤æ‚æŸ¥è¯¢æ€§èƒ½ ({iterations} æ¬¡è¿­ä»£)...")
    
    cursor = conn.cursor()
    times = []
    
    # å¤æ‚çš„JOINæŸ¥è¯¢
    complex_query = """
    SELECT 
        p.name as project_name,
        p.status,
        COUNT(t.id) as transaction_count,
        SUM(t.amount) as total_amount
    FROM projects p
    LEFT JOIN transactions t ON p.id = t.project_id
    GROUP BY p.id, p.name, p.status
    ORDER BY total_amount DESC
    LIMIT 10;
    """
    
    for i in range(iterations):
        start_time = time.time()
        cursor.execute(complex_query)
        cursor.fetchall()
        end_time = time.time()
        times.append((end_time - start_time) * 1000)
    
    cursor.close()
    
    avg_time = statistics.mean(times)
    min_time = min(times)
    max_time = max(times)
    std_dev = statistics.stdev(times) if len(times) > 1 else 0
    
    print(f"   ğŸ“Š å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ms")
    print(f"   ğŸ“Š æœ€å¿«æŸ¥è¯¢æ—¶é—´: {min_time:.2f}ms")
    print(f"   ğŸ“Š æœ€æ…¢æŸ¥è¯¢æ—¶é—´: {max_time:.2f}ms")
    print(f"   ğŸ“Š æ ‡å‡†å·®: {std_dev:.2f}ms")
    
    return {
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'std_dev': std_dev,
        'times': times
    }

def test_insert_performance(conn: psycopg2.extensions.connection, iterations: int = 100) -> Dict:
    """æµ‹è¯•æ’å…¥æ€§èƒ½"""
    print(f"\nğŸ” æµ‹è¯•æ’å…¥æ€§èƒ½ ({iterations} æ¬¡è¿­ä»£)...")
    
    cursor = conn.cursor()
    times = []
    
    # åˆ›å»ºä¸´æ—¶è¡¨è¿›è¡Œæµ‹è¯•
    cursor.execute("""
        CREATE TEMP TABLE performance_test (
            id SERIAL PRIMARY KEY,
            name TEXT,
            value INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    for i in range(iterations):
        start_time = time.time()
        cursor.execute("""
            INSERT INTO performance_test (name, value) 
            VALUES (%s, %s);
        """, (f"test_{i}", i))
        end_time = time.time()
        times.append((end_time - start_time) * 1000)
    
    # æ¸…ç†ä¸´æ—¶è¡¨
    cursor.execute("DROP TABLE performance_test;")
    conn.commit()
    cursor.close()
    
    avg_time = statistics.mean(times)
    min_time = min(times)
    max_time = max(times)
    std_dev = statistics.stdev(times) if len(times) > 1 else 0
    
    print(f"   ğŸ“Š å¹³å‡æ’å…¥æ—¶é—´: {avg_time:.2f}ms")
    print(f"   ğŸ“Š æœ€å¿«æ’å…¥æ—¶é—´: {min_time:.2f}ms")
    print(f"   ğŸ“Š æœ€æ…¢æ’å…¥æ—¶é—´: {max_time:.2f}ms")
    print(f"   ğŸ“Š æ ‡å‡†å·®: {std_dev:.2f}ms")
    
    return {
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'std_dev': std_dev,
        'times': times
    }

def test_concurrent_connections(max_connections: int = 10) -> Dict:
    """æµ‹è¯•å¹¶å‘è¿æ¥æ€§èƒ½"""
    print(f"\nğŸ” æµ‹è¯•å¹¶å‘è¿æ¥æ€§èƒ½ (æœ€å¤§ {max_connections} ä¸ªè¿æ¥)...")
    
    def test_single_connection(conn_id: int) -> Tuple[int, float, bool]:
        """æµ‹è¯•å•ä¸ªè¿æ¥"""
        start_time = time.time()
        try:
            conn = psycopg2.connect(**DB_CONFIG)
            cursor = conn.cursor()
            cursor.execute("SELECT 1;")
            cursor.fetchone()
            cursor.close()
            conn.close()
            end_time = time.time()
            return conn_id, (end_time - start_time) * 1000, True
        except Exception as e:
            end_time = time.time()
            return conn_id, (end_time - start_time) * 1000, False
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=max_connections) as executor:
        futures = [executor.submit(test_single_connection, i) for i in range(max_connections)]
        results = []
        
        for future in as_completed(futures):
            conn_id, duration, success = future.result()
            results.append((conn_id, duration, success))
    
    end_time = time.time()
    total_time = (end_time - start_time) * 1000
    
    successful_connections = sum(1 for _, _, success in results if success)
    failed_connections = max_connections - successful_connections
    
    if successful_connections > 0:
        successful_times = [duration for _, duration, success in results if success]
        avg_time = statistics.mean(successful_times)
        min_time = min(successful_times)
        max_time = max(successful_times)
    else:
        avg_time = min_time = max_time = 0
    
    print(f"   ğŸ“Š æ€»è€—æ—¶: {total_time:.2f}ms")
    print(f"   ğŸ“Š æˆåŠŸè¿æ¥: {successful_connections}/{max_connections}")
    print(f"   ğŸ“Š å¤±è´¥è¿æ¥: {failed_connections}/{max_connections}")
    if successful_connections > 0:
        print(f"   ğŸ“Š å¹³å‡è¿æ¥æ—¶é—´: {avg_time:.2f}ms")
        print(f"   ğŸ“Š æœ€å¿«è¿æ¥æ—¶é—´: {min_time:.2f}ms")
        print(f"   ğŸ“Š æœ€æ…¢è¿æ¥æ—¶é—´: {max_time:.2f}ms")
    
    return {
        'total_time': total_time,
        'successful_connections': successful_connections,
        'failed_connections': failed_connections,
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time
    }

def test_database_size(conn: psycopg2.extensions.connection) -> Dict:
    """æµ‹è¯•æ•°æ®åº“å¤§å°å’Œç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ” æµ‹è¯•æ•°æ®åº“å¤§å°å’Œç»Ÿè®¡ä¿¡æ¯...")
    
    cursor = conn.cursor()
    
    # è·å–æ•°æ®åº“å¤§å°
    cursor.execute("""
        SELECT pg_size_pretty(pg_database_size(current_database())) as db_size;
    """)
    db_size = cursor.fetchone()[0]
    
    # è·å–è¡¨æ•°é‡
    cursor.execute("""
        SELECT COUNT(*) FROM information_schema.tables 
        WHERE table_schema = 'public';
    """)
    table_count = cursor.fetchone()[0]
    
    # è·å–å„è¡¨çš„å¤§å°
    cursor.execute("""
        SELECT 
            schemaname,
            tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
        FROM pg_tables 
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
    """)
    table_sizes = cursor.fetchall()
    
    cursor.close()
    
    print(f"   ğŸ“Š æ•°æ®åº“å¤§å°: {db_size}")
    print(f"   ğŸ“Š è¡¨æ•°é‡: {table_count}")
    print(f"   ğŸ“Š å„è¡¨å¤§å°:")
    for schema, table, size in table_sizes:
        print(f"      - {table}: {size}")
    
    return {
        'db_size': db_size,
        'table_count': table_count,
        'table_sizes': table_sizes
    }

def main():
    """ä¸»å‡½æ•°"""
    print("=== æ•°æ®åº“æ€§èƒ½æµ‹è¯•è„šæœ¬ ===")
    print("æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ã€è¿æ¥æ± å’Œå¹¶å‘å¤„ç†èƒ½åŠ›")
    
    # è¿æ¥æ•°æ®åº“
    conn = connect_database()
    if not conn:
        return
    
    try:
        # æµ‹è¯•ç®€å•æŸ¥è¯¢æ€§èƒ½
        simple_query_result = test_simple_query_performance(conn)
        
        # æµ‹è¯•å¤æ‚æŸ¥è¯¢æ€§èƒ½
        complex_query_result = test_complex_query_performance(conn)
        
        # æµ‹è¯•æ’å…¥æ€§èƒ½
        insert_result = test_insert_performance(conn)
        
        # æµ‹è¯•å¹¶å‘è¿æ¥
        concurrent_result = test_concurrent_connections()
        
        # æµ‹è¯•æ•°æ®åº“å¤§å°
        size_result = test_database_size(conn)
        
        # è¾“å‡ºæ€§èƒ½è¯„ä¼°
        print("\n" + "="*50)
        print("ğŸ“‹ æ€§èƒ½è¯„ä¼°ç»“æœ:")
        
        # ç®€å•æŸ¥è¯¢æ€§èƒ½è¯„ä¼°
        if simple_query_result['avg_time'] < 1:
            print("âœ… ç®€å•æŸ¥è¯¢æ€§èƒ½: ä¼˜ç§€ (< 1ms)")
        elif simple_query_result['avg_time'] < 5:
            print("âœ… ç®€å•æŸ¥è¯¢æ€§èƒ½: è‰¯å¥½ (1-5ms)")
        elif simple_query_result['avg_time'] < 10:
            print("âš ï¸  ç®€å•æŸ¥è¯¢æ€§èƒ½: ä¸€èˆ¬ (5-10ms)")
        else:
            print("âŒ ç®€å•æŸ¥è¯¢æ€§èƒ½: è¾ƒå·® (> 10ms)")
        
        # å¤æ‚æŸ¥è¯¢æ€§èƒ½è¯„ä¼°
        if complex_query_result['avg_time'] < 10:
            print("âœ… å¤æ‚æŸ¥è¯¢æ€§èƒ½: ä¼˜ç§€ (< 10ms)")
        elif complex_query_result['avg_time'] < 50:
            print("âœ… å¤æ‚æŸ¥è¯¢æ€§èƒ½: è‰¯å¥½ (10-50ms)")
        elif complex_query_result['avg_time'] < 100:
            print("âš ï¸  å¤æ‚æŸ¥è¯¢æ€§èƒ½: ä¸€èˆ¬ (50-100ms)")
        else:
            print("âŒ å¤æ‚æŸ¥è¯¢æ€§èƒ½: è¾ƒå·® (> 100ms)")
        
        # æ’å…¥æ€§èƒ½è¯„ä¼°
        if insert_result['avg_time'] < 5:
            print("âœ… æ’å…¥æ€§èƒ½: ä¼˜ç§€ (< 5ms)")
        elif insert_result['avg_time'] < 20:
            print("âœ… æ’å…¥æ€§èƒ½: è‰¯å¥½ (5-20ms)")
        elif insert_result['avg_time'] < 50:
            print("âš ï¸  æ’å…¥æ€§èƒ½: ä¸€èˆ¬ (20-50ms)")
        else:
            print("âŒ æ’å…¥æ€§èƒ½: è¾ƒå·® (> 50ms)")
        
        # å¹¶å‘æ€§èƒ½è¯„ä¼°
        if concurrent_result['successful_connections'] == concurrent_result['successful_connections'] + concurrent_result['failed_connections']:
            print("âœ… å¹¶å‘è¿æ¥æ€§èƒ½: ä¼˜ç§€ (100% æˆåŠŸ)")
        elif concurrent_result['successful_connections'] / (concurrent_result['successful_connections'] + concurrent_result['failed_connections']) > 0.8:
            print("âœ… å¹¶å‘è¿æ¥æ€§èƒ½: è‰¯å¥½ (> 80% æˆåŠŸ)")
        elif concurrent_result['successful_connections'] / (concurrent_result['successful_connections'] + concurrent_result['failed_connections']) > 0.5:
            print("âš ï¸  å¹¶å‘è¿æ¥æ€§èƒ½: ä¸€èˆ¬ (50-80% æˆåŠŸ)")
        else:
            print("âŒ å¹¶å‘è¿æ¥æ€§èƒ½: è¾ƒå·® (< 50% æˆåŠŸ)")
        
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        if simple_query_result['avg_time'] > 5:
            print("   - è€ƒè™‘æ·»åŠ æ•°æ®åº“ç´¢å¼•")
        if complex_query_result['avg_time'] > 50:
            print("   - ä¼˜åŒ–å¤æ‚æŸ¥è¯¢SQL")
        if insert_result['avg_time'] > 20:
            print("   - è€ƒè™‘æ‰¹é‡æ’å…¥æ“ä½œ")
        if concurrent_result['failed_connections'] > 0:
            print("   - æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± é…ç½®")
        
    finally:
        conn.close()
        print("\nğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    main()
